{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7229648,"sourceType":"datasetVersion","datasetId":2503025},{"sourceId":7490795,"sourceType":"datasetVersion","datasetId":821893}],"dockerImageVersionId":30559,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport glob\nimport shutil\nimport cv2\nimport os\nfrom tqdm import tqdm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-17T14:09:33.030208Z","iopub.execute_input":"2024-02-17T14:09:33.031176Z","iopub.status.idle":"2024-02-17T14:09:33.745366Z","shell.execute_reply.started":"2024-02-17T14:09:33.031134Z","shell.execute_reply":"2024-02-17T14:09:33.744593Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"%pip install ultralytics\nimport ultralytics\nultralytics.checks()","metadata":{"execution":{"iopub.status.busy":"2024-02-17T14:09:33.747094Z","iopub.execute_input":"2024-02-17T14:09:33.747481Z","iopub.status.idle":"2024-02-17T14:09:49.047100Z","shell.execute_reply.started":"2024-02-17T14:09:33.747455Z","shell.execute_reply":"2024-02-17T14:09:49.046221Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Ultralytics YOLOv8.1.14 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\nSetup complete ✅ (4 CPUs, 31.4 GB RAM, 5432.1/8062.4 GB disk)\n","output_type":"stream"}]},{"cell_type":"code","source":"from ultralytics import YOLO","metadata":{"execution":{"iopub.status.busy":"2024-02-17T14:09:49.048241Z","iopub.execute_input":"2024-02-17T14:09:49.048627Z","iopub.status.idle":"2024-02-17T14:09:49.053245Z","shell.execute_reply.started":"2024-02-17T14:09:49.048601Z","shell.execute_reply":"2024-02-17T14:09:49.052302Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import os\nimport os.path as pt\nimport random\nimport shutil\n\nimport pandas as pd\nimport yaml\nfrom tqdm import tqdm\n\n\ndef exists(path):\n    if not os.path.exists(path):\n        os.makedirs(path)\n\n\ndef move_image(src_folder, dest_folder, image_name):\n    # 源文件的路径\n    src_path = os.path.join(src_folder, image_name)\n\n    # 目标文件的路径\n    dest_path = os.path.join(dest_folder, image_name)\n\n    # 移动文件\n    shutil.copy(src_path, dest_path)\n\n\ndef progress(list_, img_target, label_target, labels, data_path):\n    yy = tqdm(list_)\n    for csv_filename in yy:\n        df = pd.read_csv(os.path.join(data_path, csv_filename))\n        csv_name = csv_filename.split('.')[0]\n        txt_file_name = csv_name + '.txt'\n        img_file_name = csv_name + '.jpg'\n\n        for i in df.values:\n            # i-->[file_name, w, h, label, x1, y1, x2, y2]\n            \n            txt_name, w, h, label, x1, y1, x2, y2 = i\n            \n            move_image(data_path, img_target, img_file_name)\n            if label not in labels:\n                labels.append(label)\n            label = labels.index(label)\n\n            x_ = (x1 + x2) / (2 * w)\n            y_ = (y1 + y2) / (2 * h)\n            w_ = (x2 - x1) / w\n            h_ = (y2 - y1) / h\n            with open(pt.join(label_target, txt_file_name), 'a') as f:\n                f.write(f\"{label} {x_} {y_} {w_} {h_}\\n\")\n\n\ndef generate_yaml(train_path, val_path, names, nc, base):\n    data = {\n        \"train\": train_path,\n        \"val\": val_path,\n        \"names\": names,\n        \"nc\": nc\n    }\n\n    with open(pt.join(base, 'mydata.yaml'), 'w') as outfile:\n        yaml.dump(data, outfile, default_flow_style=False)\n\n\ndef main(save_path, source_path, scale):\n    # 创建保存txt的路径\n    base = save_path\n    img_path = pt.join(base, 'images')\n    label_path = pt.join(base, 'labels')\n    img_path_train = pt.join(img_path, 'train')\n    img_path_val = pt.join(img_path, 'val')\n    label_path_train = pt.join(label_path, 'train')\n    label_path_val = pt.join(label_path, 'val')\n    exists(img_path_train)\n    exists(img_path_val)\n    exists(label_path_train)\n    exists(label_path_val)\n\n    data_path = source_path\n    filenames = os.listdir(data_path)\n    csv_filenames = [filename for filename in filenames if filename.endswith('.csv')]\n\n    # 按比例将csv文件分成train和val\n    labels1 = {}\n    for csv_name in csv_filenames:\n        df = pd.read_csv(os.path.join(data_path, csv_name))\n        for i in df.values:\n            txt_name, w, h, label, x1, y1, x2, y2 = i\n            if label in labels1:\n                labels1[label].append(csv_name)\n            else:\n                labels1[label] = [csv_name]\n            break\n\n    train_files = []\n    valid_files = []\n    for i in labels1.values():\n        random.shuffle(i)\n        num_train = int(len(i) * scale)  # scale learning rate\n\n        train_files.extend(i[:num_train])\n        valid_files.extend(i[num_train:])\n\n    Alabels = []\n    print(len(train_files) / len(valid_files))\n\n    progress(train_files, img_path_train, label_path_train, Alabels, data_path)\n    progress(valid_files, img_path_val, label_path_val, Alabels, data_path)\n\n    names = {i: name for i, name in enumerate(Alabels)}\n    nc = len(Alabels)\n    generate_yaml(img_path_train, img_path_val, names, nc, base)\n\n\nif __name__ == \"__main__\":\n    main(save_path='/kaggle/working/data',\n         source_path='/kaggle/input/militaryaircraftdetectiondataset/dataset',\n         scale=0.9\n         )","metadata":{"execution":{"iopub.status.busy":"2024-02-17T14:09:49.054527Z","iopub.execute_input":"2024-02-17T14:09:49.054798Z","iopub.status.idle":"2024-02-17T14:15:50.202179Z","shell.execute_reply.started":"2024-02-17T14:09:49.054774Z","shell.execute_reply":"2024-02-17T14:15:50.201254Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"8.866615853658537\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 11633/11633 [04:38<00:00, 41.76it/s]\n100%|██████████| 1312/1312 [00:30<00:00, 43.10it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"model = YOLO('yolov8m.pt')\n\n# default params\n# results = model.train(data='/kaggle/working/data/mydata.yaml', epochs=15, imgsz=640, lrf=0.1)\n\n# most best params 0.79 acc\n# results = model.train(data='/kaggle/working/data/mydata.yaml', epochs=15, imgsz=800)\n\n# now test params\nresults = model.train(data='/kaggle/working/data/mydata.yaml', epochs=15, imgsz=860)    # 0.821 acc\n","metadata":{"execution":{"iopub.status.busy":"2024-02-17T14:15:50.204272Z","iopub.execute_input":"2024-02-17T14:15:50.204570Z","iopub.status.idle":"2024-02-17T17:22:25.852713Z","shell.execute_reply.started":"2024-02-17T14:15:50.204544Z","shell.execute_reply":"2024-02-17T17:22:25.851216Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Downloading https://github.com/ultralytics/assets/releases/download/v8.1.0/yolov8m.pt to 'yolov8m.pt'...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 49.7M/49.7M [00:00<00:00, 278MB/s]\n","output_type":"stream"},{"name":"stdout","text":"Ultralytics YOLOv8.1.14 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8m.pt, data=/kaggle/working/data/mydata.yaml, epochs=15, time=None, patience=50, batch=16, imgsz=860, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"name":"stdout","text":"Overriding model.yaml nc=80 with nc=46\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n 22        [15, 18, 21]  1   3802330  ultralytics.nn.modules.head.Detect           [46, [192, 384, 576]]         \nModel summary: 295 layers, 25882954 parameters, 25882938 gradients, 79.2 GFLOPs\n\nTransferred 469/475 items from pretrained weights\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\nFreezing layer 'model.22.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\nDownloading https://github.com/ultralytics/assets/releases/download/v8.1.0/yolov8n.pt to 'yolov8n.pt'...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6.23M/6.23M [00:00<00:00, 106MB/s]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\nWARNING ⚠️ imgsz=[860] must be multiple of max stride 32, updating to [864]\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/data/labels/train... 11627 images, 0 backgrounds, 6 corrupt: 100%|██████████| 11633/11633 [00:09<00:00, 1206.52it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/data/images/train/014240b10dffa805240c72655e357866.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/data/images/train/08b11baa46e2d9185dd9ee4af5ce89fc.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/data/images/train/14dd66103e6399d3754f6bcb53fdead2.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/data/images/train/1e8b43deca87d25180aba67557735c01.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/data/images/train/2044a7ebe3d8132a8bce492f42bbde1d.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/data/images/train/2790a93ba1210aaaa09931b951d2376a.jpg: ignoring corrupt image/label: image file is truncated (1 bytes not processed)\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/data/images/train/2b80e26d24d077d2877caf97756db72d.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/data/images/train/2d63eab2755538fa1e830f283eaefaa2.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/data/images/train/33ac074469512ac279d599cdd1157ec1.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/data/images/train/33e9eebd84173751f4de6d10c7cab0c4.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/data/images/train/37cef25b6530c45a02acb1d30b56a15b.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/data/images/train/393ff29b0978ed06efe8911631e1791e.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/data/images/train/3cda68798923952e40d8ec720d436207.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/data/images/train/4075b1896e913e85d31001f6fbe2336e.jpg: ignoring corrupt image/label: image file is truncated (27 bytes not processed)\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/data/images/train/43718f36b529dc159a51b479e40eba8c.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/data/images/train/44a429b8b5a6165e21405347ed412649.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/data/images/train/4e9909c2d98befa16315dd814e990f22.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/data/images/train/4ef1fa6020f23711cc0e06dc1e7dfdbc.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/data/images/train/4f6335afb880904ed5ebae7ed55fd81b.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/data/images/train/53407a519525715fe10f141958cd543a.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/data/images/train/548f7e5aead26331a842402c2a2e1abf.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/data/images/train/59e1d43b57f90388879e9da7599b3f75.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/data/images/train/5ed8dd35ea5346ac1dc70a726411cd04.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/data/images/train/68bdc6a16450c3c01fff8bcce9146948.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/data/images/train/767d90ca1d3649ff1732376341d961ca.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/data/images/train/7a1054ee4e1158ad3bb2d2d7b1308cc6.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/data/images/train/7e722a1478e888c2d0b8bffeb7bbb154.jpg: ignoring corrupt image/label: image file is truncated (1 bytes not processed)\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/data/images/train/7f35d5ac8df852e80c8a35c061ec9473.jpg: ignoring corrupt image/label: image file is truncated (3 bytes not processed)\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/data/images/train/80ab29de242d75a6a3b08cf3eb08a415.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/data/images/train/81132e8d96bf76ceac037b03839c82ab.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/data/images/train/88c2d4d1d4f5ab539558cf4129cd9ef2.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/data/images/train/92711e787a2bf1173dc4afb5f40418e4.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/data/images/train/949bcbb399e20913e4e02230b00b6bdd.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/data/images/train/a912ac8f44762b44a4916ad011437fbb.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/data/images/train/ac7b8662ed3fb8b116f5db729e0c5a50.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/data/images/train/b70799e73139409aeba1392d03ef4be9.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/data/images/train/c28440d244bb289b61b19c6070657d6c.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/data/images/train/c95b4fd51b689de2f0d7b161b11b7c9e.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/data/images/train/cdfa23ff0a31e26db5af2ea32a07317e.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/data/images/train/d317123762f868d87ef908cff801fe6f.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/data/images/train/d37af747d93eb94c18d0c7150b845af2.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/data/images/train/d4a19e6524ed06786bc75802388069cd.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/data/images/train/d9005561d68c4a89f95a3257374a0b2f.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/data/images/train/e704da53011ed94a1644bec7ffc904e9.jpg: ignoring corrupt image/label: image file is truncated (4 bytes not processed)\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/data/images/train/f2ea4aad6f8980b2f9254cda9eb13e9b.jpg: ignoring corrupt image/label: image file is truncated (12 bytes not processed)\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/data/images/train/f6158735ad61f83ac6ad45e4032d3068.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/data/images/train/fe26e23dabe4618337df064573717487.jpg: corrupt JPEG restored and saved\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/data/labels/train.cache\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/data/labels/val... 1312 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1312/1312 [00:01<00:00, 925.99it/s] ","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/working/data/images/val/0659b84f8272d49753431dc808b8d4e1.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/working/data/images/val/87825161a8c72af4e78e0a18be245e34.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/working/data/images/val/98fcfb7b9525b96ab14dc16971c9c039.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/working/data/images/val/ae14f65bd7744dbb8dc0931ee59fb619.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/working/data/images/val/b6c3bb6faa6ef9065bcf32683404e621.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/working/data/images/val/ba79a148bef8b8cae906f16d9d55a27b.jpg: corrupt JPEG restored and saved\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/data/labels/val.cache\nPlotting labels to runs/detect/train/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.0002, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\nImage sizes 864 train, 864 val\nUsing 4 dataloader workers\nLogging results to \u001b[1mruns/detect/train\u001b[0m\nStarting training for 15 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       1/15      12.2G     0.7778      3.594      1.203         24        864: 100%|██████████| 727/727 [11:49<00:00,  1.02it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 41/41 [00:37<00:00,  1.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       1312       2145      0.184      0.259      0.161      0.138\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       2/15      12.4G     0.7676      2.527      1.175         51        864: 100%|██████████| 727/727 [11:43<00:00,  1.03it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 41/41 [00:39<00:00,  1.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       1312       2145      0.299      0.342      0.259      0.219\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       3/15      12.4G     0.7752      2.271      1.173         49        864: 100%|██████████| 727/727 [11:41<00:00,  1.04it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 41/41 [00:36<00:00,  1.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       1312       2145      0.307      0.372      0.313      0.256\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       4/15      12.4G     0.7538      2.073      1.161         31        864: 100%|██████████| 727/727 [11:37<00:00,  1.04it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 41/41 [00:37<00:00,  1.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       1312       2145      0.496      0.386       0.43      0.367\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       5/15      12.3G     0.7246      1.907      1.138         44        864: 100%|██████████| 727/727 [11:42<00:00,  1.04it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 41/41 [00:37<00:00,  1.10it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       1312       2145      0.539      0.456      0.502      0.436\nClosing dataloader mosaic\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       6/15      12.4G     0.6193      1.663      1.078         20        864: 100%|██████████| 727/727 [11:39<00:00,  1.04it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 41/41 [00:38<00:00,  1.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       1312       2145      0.607      0.465      0.536      0.468\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       7/15      12.3G     0.5774      1.474      1.048         14        864: 100%|██████████| 727/727 [11:36<00:00,  1.04it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 41/41 [00:37<00:00,  1.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       1312       2145      0.594      0.541      0.597      0.527\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       9/15      12.3G     0.5203       1.19      1.005         14        864: 100%|██████████| 727/727 [11:36<00:00,  1.04it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 41/41 [00:36<00:00,  1.13it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1312       2145      0.698      0.599      0.677      0.604\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      10/15      12.4G      0.493      1.044     0.9878         15        864: 100%|██████████| 727/727 [11:36<00:00,  1.04it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 41/41 [00:37<00:00,  1.10it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1312       2145      0.711      0.633      0.713      0.634\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      11/15      12.3G      0.468     0.9399     0.9704         14        864: 100%|██████████| 727/727 [11:35<00:00,  1.05it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 41/41 [00:35<00:00,  1.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       1312       2145      0.797       0.63      0.744       0.67\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      12/15      12.4G     0.4501     0.8472     0.9563         15        864: 100%|██████████| 727/727 [11:35<00:00,  1.04it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 41/41 [00:36<00:00,  1.13it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1312       2145      0.783      0.664      0.762       0.69\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      13/15      12.3G      0.422      0.744     0.9374         25        864: 100%|██████████| 727/727 [11:34<00:00,  1.05it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 41/41 [00:36<00:00,  1.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       1312       2145       0.79      0.693      0.789      0.722\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      14/15      12.4G     0.4045     0.6554     0.9261         17        864: 100%|██████████| 727/727 [11:38<00:00,  1.04it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 41/41 [00:36<00:00,  1.12it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1312       2145      0.845       0.67      0.796      0.727\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      15/15      12.3G     0.3829     0.5799      0.913         20        864: 100%|██████████| 727/727 [11:37<00:00,  1.04it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 41/41 [00:35<00:00,  1.15it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1312       2145      0.831      0.713      0.821      0.751\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n15 epochs completed in 3.087 hours.\nOptimizer stripped from runs/detect/train/weights/last.pt, 52.1MB\nOptimizer stripped from runs/detect/train/weights/best.pt, 52.1MB\n\nValidating runs/detect/train/weights/best.pt...\nUltralytics YOLOv8.1.14 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\nModel summary (fused): 218 layers, 25866394 parameters, 0 gradients, 78.8 GFLOPs\n","output_type":"stream"},{"name":"stderr","text":"                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 41/41 [00:37<00:00,  1.10it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       1312       2145      0.828      0.713      0.821      0.751\n                EF2000       1312         51      0.776      0.549      0.752      0.709\n                   F16       1312        120      0.749      0.542      0.729      0.628\n                   F18       1312        106      0.792      0.783       0.86      0.739\n                    P3       1312         23      0.893      0.652      0.786      0.775\n                 A400M       1312         38      0.864      0.711      0.811      0.762\n                   B52       1312         64      0.893      0.786      0.894      0.796\n               Tornado       1312         45      0.746        0.6       0.65      0.613\n                  Tu95       1312         22      0.897       0.79      0.849      0.777\n                  Su34       1312         30      0.903      0.567      0.743      0.661\n                   F15       1312        108      0.649       0.75      0.819      0.758\n                   F35       1312        105      0.713      0.752      0.816      0.736\n                Rafale       1312         40      0.578      0.625      0.694      0.655\n                 Tu160       1312         21      0.818      0.855      0.842      0.795\n            Mirage2000       1312         37      0.796      0.676      0.784      0.724\n                  C130       1312         81       0.94      0.776      0.895      0.845\n                 JAS39       1312         43      0.749      0.628      0.717      0.658\n                   A10       1312         56      0.857      0.748      0.856      0.715\n                 KC135       1312         11      0.583      0.364      0.574      0.555\n                    F4       1312         58      0.892      0.709      0.809       0.72\n                  F117       1312         44       0.96      0.544      0.858      0.776\n                   V22       1312        102      0.921      0.765       0.89      0.696\n                    B1       1312         67      0.907      0.821       0.94      0.783\n                    B2       1312         44      0.946      0.803      0.892      0.818\n                   F22       1312         69      0.787      0.594      0.789      0.693\n                   C17       1312         64      0.648      0.718      0.773      0.708\n                  AV8B       1312         33      0.908      0.727      0.868      0.796\n                   US2       1312         63      0.899      0.846      0.934      0.873\n                 Be200       1312         25       0.92      0.915      0.953      0.881\n                 AG600       1312         19      0.898      0.925      0.985      0.953\n                    C5       1312         32      0.733      0.719      0.768      0.701\n                   MQ9       1312         26      0.727      0.769      0.872      0.837\n                    E2       1312         42      0.865      0.833      0.905      0.787\n                    C2       1312         86      0.948      0.852      0.969      0.934\n                  SR71       1312         24      0.815      0.917      0.963       0.89\n                   F14       1312         33      0.669      0.576        0.7      0.662\n                    E7       1312         15      0.869        0.8      0.897      0.742\n                  YF23       1312         19      0.922      0.895      0.983      0.977\n                Vulcan       1312         57      0.878      0.561      0.729      0.676\n                    U2       1312         23      0.768      0.826      0.823      0.759\n                   RQ4       1312         23      0.866      0.913       0.92      0.837\n                 Mig31       1312         44      0.844        0.5      0.662      0.587\n                  Su57       1312         30      0.894      0.567       0.75      0.705\n                   J20       1312         44      0.899      0.812      0.892      0.868\n                  XB70       1312         19      0.941      0.847      0.889      0.831\n                  Su25       1312         10      0.799      0.398      0.559      0.504\n                   J10       1312         29      0.767      0.517      0.725       0.63\nSpeed: 0.4ms preprocess, 12.8ms inference, 0.0ms loss, 1.4ms postprocess per image\nResults saved to \u001b[1mruns/detect/train\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"print(\"results\")\nprint(results.results_dict)\nres_dict = results.results_dict\nprint(res_dict.values())\nscore_precision, score_recall, score_mAP50, score_mAP50_95, score_fitness = list(res_dict.values())\n\nround_score_mAP50 = round(score_mAP50, 3)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-17T17:22:25.855105Z","iopub.execute_input":"2024-02-17T17:22:25.855421Z","iopub.status.idle":"2024-02-17T17:22:25.863954Z","shell.execute_reply.started":"2024-02-17T17:22:25.855396Z","shell.execute_reply":"2024-02-17T17:22:25.862895Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"results\n{'metrics/precision(B)': 0.8279442972975345, 'metrics/recall(B)': 0.7134903486440998, 'metrics/mAP50(B)': 0.8210655451973937, 'metrics/mAP50-95(B)': 0.7505190080902957, 'fitness': 0.7575736618010055}\ndict_values([0.8279442972975345, 0.7134903486440998, 0.8210655451973937, 0.7505190080902957, 0.7575736618010055])\n","output_type":"stream"}]},{"cell_type":"code","source":"# Export working dir\nimport shutil\nimport datetime\nimport pytz\n\ndirectory_path = \"/kaggle/working/runs\"\n\n# Specify Thailand timezone\nthailand_tz = pytz.timezone('Asia/Bangkok')\n\n# Get current time in Thailand\nnow_thailand = datetime.datetime.now(thailand_tz)\ndate_string = now_thailand.strftime(\"%Y-%m-%d\")\nprint(date_string)\n\noutput_filename = f\"\"\"skw_notebook_{date_string}_{string_score_mAP50}\"\"\"\nprint(\"zipping file \", output_filename)\nshutil.make_archive(output_filename, 'zip', directory_path)\nprint(\"zipping file completed\")\n%ls\n","metadata":{"execution":{"iopub.status.busy":"2024-02-17T17:22:25.865403Z","iopub.execute_input":"2024-02-17T17:22:25.865707Z","iopub.status.idle":"2024-02-17T17:22:32.607571Z","shell.execute_reply.started":"2024-02-17T17:22:25.865681Z","shell.execute_reply":"2024-02-17T17:22:32.606468Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"2024-02-18\nzipping file  skw_notebook_2024-02-18_0821\nzipping file completed\n\u001b[0m\u001b[01;34mdata\u001b[0m/  \u001b[01;34mruns\u001b[0m/  skw_notebook_2024-02-18_0821.zip  yolov8m.pt  yolov8n.pt\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport shutil\n\n\ndef remove_files(path):\n    \n    need_to_delete = path\n    \n    # List all files and directories in the working directory\n    files_and_directories = os.listdir(need_to_delete)\n\n    # Iterate through the list and remove each file or directory\n    for item in files_and_directories:\n        item_path = os.path.join(need_to_delete, item)\n\n        # Check if it's a file or directory before removing\n        if os.path.isfile(item_path):\n            os.remove(item_path)\n        elif os.path.isdir(item_path):\n            shutil.rmtree(item_path)\n\n    print(f\"All files in {need_to_delete} directory have been cleared.\")\n\n    \n    \n# Get the current working directory\npath_to_delete = '/kaggle/working/'\n\n# remove_files(path_to_delete)\n\nprint(\"end\")","metadata":{"execution":{"iopub.status.busy":"2024-02-17T17:22:32.609507Z","iopub.execute_input":"2024-02-17T17:22:32.610366Z","iopub.status.idle":"2024-02-17T17:22:32.618391Z","shell.execute_reply.started":"2024-02-17T17:22:32.610316Z","shell.execute_reply":"2024-02-17T17:22:32.617474Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"end\n","output_type":"stream"}]}]}